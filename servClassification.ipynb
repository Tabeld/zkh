{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O14vQpTN800"
      },
      "outputs": [],
      "source": [
        "import re, json, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
        "from scipy.sparse import hstack\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Конфиг пути и тд"
      ],
      "metadata": {
        "id": "yRMBXLodOVvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_CSV = \"data/train.csv\"      # колонки: text,label\n",
        "TEXT_COL = \"text\"\n",
        "LABEL_COL = \"label\"\n",
        "MAJOR_CLASS = \"ОДУ\"              # мажорный класс (переименуй под свои данные)\n",
        "OUT_DIR = Path(\"artifacts\"); OUT_DIR.mkdir(exist_ok=True)"
      ],
      "metadata": {
        "id": "gciu5M4qOGST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лексиконы\n",
        "- Лексиконы - ключевые слова (правила) по которым определяем какие классы какой службе соответствуют.\n",
        "- Это не жесткие правила а лишь помощь классификатору"
      ],
      "metadata": {
        "id": "qywbaiETOj8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LEX: Dict[str, List[str]] = {\n",
        "    \"Сантехника\": [r\"\\bтруба\\b\", r\"\\bпрорвал[оась]\\b\", r\"\\bтеч[её]\\b\", r\"\\bзатоп(ил[аи]|ило)\\b\",\n",
        "                   r\"\\b(гвс|хвс|вода)\\b\"],\n",
        "    \"Электрика\":  [r\"\\bкорот(ит|нуло)\\b\", r\"\\bзамыкан(ие|ия)\\b\", r\"\\bискрит\\b\", r\"\\bвыбил[аи]\\b.*\\bпробк[и]\\b\",\n",
        "                   r\"\\bщиток\\b\", r\"\\bавтомат(ы)?\\b\"],\n",
        "    \"Отопление\":  [r\"\\bнет отоплен\", r\"\\bбатаре(я|и) (холод|лед)\", r\"\\bрадиатор\\b\", r\"\\bкотел\"],\n",
        "    \"Лифт\":       [r\"\\bлифт\\b\", r\"\\bзастрял\\b\", r\"\\bне работает лифт\\b\"],\n",
        "    \"ОДУ\":        [r\"\\bподъезд\\b\", r\"\\bдвор\\b\", r\"\\bуборк[аи]\\b\", r\"\\bсосед(и|ям|ями)\\b\", r\"\\bшум\\b\"],\n",
        "}"
      ],
      "metadata": {
        "id": "2AQZQdEkOfQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# МАШИН ЛЕРНИНГ!!!"
      ],
      "metadata": {
        "id": "NYgnra4CPMdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(s: str) -> str:\n",
        "    s = s.lower()\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s"
      ],
      "metadata": {
        "id": "8jvPi4EBPFGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `build_rule_feats(texts: List[str], classes: List[str]) -> np.ndarray`\n",
        "\n",
        "**Назначение:**  \n",
        "Генерирует дополнительные \"правильные\" (rule-based) признаки для каждого текста на основе заранее заданных словарей/регулярных выражений (`LEX`).  \n",
        "Каждый признак — это количество совпадений текста с шаблонами, характерными для определённого класса.\n",
        "\n",
        "**Параметры:**\n",
        "- `texts` (`List[str]`): Список текстовых обращений пользователей.\n",
        "- `classes` (`List[str]`): Список всех классов (меток), для которых будут считаться совпадения.\n",
        "\n",
        "**Возвращает:**\n",
        "- `np.ndarray` формы `(N, C)`:\n",
        "  - `N` — количество текстов,\n",
        "  - `C` — количество классов.  \n",
        "  Каждое значение `M[i, j]` — количество паттернов из словаря класса `classes[j]`, найденных в тексте `texts[i]`.\n",
        "\n",
        "**Алгоритм работы:**\n",
        "1. Для каждого класса из `classes` берутся регулярные выражения из глобального словаря `LEX` и компилируются для ускорения поиска.\n",
        "2. Создаётся матрица признаков `M` из нулей (`float32`).\n",
        "3. Для каждого текста и каждого класса считается, сколько паттернов найдено в тексте.\n",
        "4. Результирующая матрица возвращается в виде `numpy.ndarray`.\n",
        "\n",
        "**Пример:**\n",
        "```python\n",
        "texts = [\"Прорвало трубу в подвале\", \"Выбило пробки\"]\n",
        "classes = [\"Сантехника\", \"Электрика\"]\n",
        "\n",
        "M = build_rule_feats(texts, classes)\n",
        "# M[0,0] может быть >0 (нашли слова про трубы)\n",
        "# M[0,1] = 0 (нет электрических терминов)\n",
        "```"
      ],
      "metadata": {
        "id": "VByZ8ag-RPsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_rule_feats(texts: List[str], classes: List[str]):\n",
        "    # матрица N x C: сколько паттернов класса сработало в тексте\n",
        "    comp = {c: [re.compile(p, re.I) for p in LEX.get(c, [])] for c in classes}\n",
        "    M = np.zeros((len(texts), len(classes)), dtype=np.float32)\n",
        "    for i, t in enumerate(texts):\n",
        "        for j, c in enumerate(classes):\n",
        "            if comp[c]:\n",
        "                M[i, j] = sum(1 for pat in comp[c] if pat.search(t))\n",
        "    return M"
      ],
      "metadata": {
        "id": "IkdDGnszPQzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`pick_with_majority_threshold(proba: np.ndarray, classes: np.ndarray, major: str, tau: float) -> np.ndarray`\n",
        "\n",
        "**Назначение:**\n",
        "\n",
        "Постобработка предсказаний модели для борьбы с дисбалансом классов.\n",
        "Если модель выбрала мажорный класс (major), но уверенность ниже порога (tau),\n",
        "заменяет предсказание на второй по вероятности класс.\n",
        "\n",
        "**Параметры:**\n",
        "\n",
        " - `proba (np.ndarray):` Матрица вероятностей формы (N, C) — результат predict_proba().\n",
        "\n",
        " - `classes (np.ndarray):` Массив с названиями классов в том же порядке, что в proba.\n",
        "\n",
        " - `major (str):` Имя мажорного класса, вероятность которого нужно проверять.\n",
        "\n",
        " - `tau (float):` Порог уверенности для мажорного класса (0 < tau ≤ 1).\n",
        "\n",
        "**Возвращает:**\n",
        "\n",
        " - `np.ndarray формы (N,):` Индексы классов после применения порогового правила.\n",
        "\n",
        "**Алгоритм работы:**\n",
        "\n",
        "  - Определяется индекс мажорного класса (idx_major).\n",
        "\n",
        "  - Для каждого предсказания:\n",
        "\n",
        "       - Если топ-1 класс — мажорный и его вероятность < tau:\n",
        "\n",
        "           - Класс заменяется на второй по вероятности (argsort по убыванию).\n",
        "\n",
        "       - Иначе — остаётся топ-1 класс.\n",
        "\n",
        "   - Возвращается массив индексов выбранных классов.\n",
        "\n",
        "**Пример:**\n",
        "```python\n",
        "proba = np.array([\n",
        "    [0.6, 0.3, 0.1],  # Мажорный класс с низкой уверенностью\n",
        "    [0.9, 0.05, 0.05] # Мажорный класс с высокой уверенностью\n",
        "])\n",
        "classes = np.array([\"ОДУ\", \"Сантехника\", \"Электрика\"])\n",
        "out_idx = pick_with_majority_threshold(proba, classes, major=\"ОДУ\", tau=0.7)\n",
        "# out_idx[0] будет указывать на \"Сантехника\", out_idx[1] останется \"ОДУ\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Ygz2oyAfRiBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pick_with_majority_threshold(proba: np.ndarray, classes: np.ndarray, major: str, tau: float):\n",
        "    idx_major = list(classes).index(major)\n",
        "    top1 = proba.argmax(1)\n",
        "    out = top1.copy()\n",
        "    for i in range(len(out)):\n",
        "        if classes[out[i]] == major and proba[i, idx_major] < tau:\n",
        "            # берём 2-й по вероятности\n",
        "            out[i] = np.argsort(proba[i])[::-1][1]\n",
        "    return out"
      ],
      "metadata": {
        "id": "qvgZVKTwPY_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(DATA_CSV)\n",
        "df = df[[TEXT_COL, LABEL_COL]].dropna()\n",
        "df[TEXT_COL] = df[TEXT_COL].astype(str).map(normalize_text)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    df[TEXT_COL].values, df[LABEL_COL].values, test_size=0.2, stratify=df[LABEL_COL], random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "WeazSiQGPdCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1) TF-IDF по словам (1-2 граммы) ===\n",
        "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=3, max_df=0.9)\n",
        "Xtr_tfidf = tfidf.fit_transform(X_train)\n",
        "Xva_tfidf = tfidf.transform(X_val)"
      ],
      "metadata": {
        "id": "CpZcM5EgPkQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 2) Rule-feats ===\n",
        "classes_sorted = sorted(pd.unique(df[LABEL_COL]))\n",
        "Xtr_rule = build_rule_feats(list(X_train), classes_sorted)\n",
        "Xva_rule = build_rule_feats(list(X_val), classes_sorted)\n",
        "# совместим sparse + dense\n",
        "Xtr = hstack([Xtr_tfidf, Xtr_rule])\n",
        "Xva = hstack([Xva_tfidf, Xva_rule])"
      ],
      "metadata": {
        "id": "-mhIB7YKPsqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 3) Веса классов и/или sample_weight ===\n",
        "# class_weight=\"balanced\" уже хорошо; дополнительно можно снизить вклад мажора:\n",
        "sample_weight = np.ones(len(y_train), dtype=np.float32)\n",
        "sample_weight[np.array(y_train) == MAJOR_CLASS] = 0.5  # подстрой"
      ],
      "metadata": {
        "id": "qd1AvJBaP6_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(\n",
        "        max_iter=2000, class_weight=\"balanced\", n_jobs=-1, solver=\"lbfgs\", multi_class=\"auto\"\n",
        "    )\n",
        "    clf.fit(Xtr, y_train, sample_weight=sample_weight)\n"
      ],
      "metadata": {
        "id": "4YDStBuOQB1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proba = clf.predict_proba(Xva)\n",
        "y_pred_plain = clf.classes_[proba.argmax(1)]"
      ],
      "metadata": {
        "id": "BIjczmRNQD85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_tau, best_f1, best_pred = 0.0, -1.0, y_pred_plain\n",
        "for tau in np.linspace(0.4, 0.75, 8):  # сетка порогов\n",
        "    pred_idx = pick_with_majority_threshold(proba, clf.classes_, MAJOR_CLASS, tau)\n",
        "    y_pred = clf.classes_[pred_idx]\n",
        "    f1 = f1_score(y_val, y_pred, average=\"macro\")\n",
        "    if f1 > best_f1:\n",
        "        best_tau, best_f1, best_pred = float(tau), float(f1), y_pred"
      ],
      "metadata": {
        "id": "GER_wvPYQId-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Без порога ===\")\n",
        "print(classification_report(y_val, y_pred_plain, digits=3))\n",
        "print(\"\\n=== С порогом для мажора (τ=%.2f) — macro-F1=%.3f ===\" % (best_tau, best_f1))\n",
        "print(classification_report(y_val, best_pred, digits=3))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_val, best_pred, labels=clf.classes_))"
      ],
      "metadata": {
        "id": "WLfZlSbNQSWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Экспорт модели"
      ],
      "metadata": {
        "id": "KkQehCGvQurV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump({\"tfidf\": tfidf, \"clf\": clf, \"classes\": clf.classes_, \"tau_major\": best_tau,\n",
        "             \"major_class\": MAJOR_CLASS, \"lex\": LEX},\n",
        "            OUT_DIR / \"service_clf.joblib\")\n",
        "(OUT_DIR / \"report.json\").write_text(json.dumps({\n",
        "    \"tau_major\": best_tau,\n",
        "    \"macro_f1\": best_f1}, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "print(\"\\nSaved:\", OUT_DIR / \"service_clf.joblib\")"
      ],
      "metadata": {
        "id": "q3eq9sxgQe5K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}